{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fec303",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.025902,
     "end_time": "2023-06-05T22:53:11.861085",
     "exception": false,
     "start_time": "2023-06-05T22:53:11.835183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af20aa66",
   "metadata": {
    "papermill": {
     "duration": 0.087843,
     "end_time": "2023-06-05T22:53:11.953566",
     "exception": false,
     "start_time": "2023-06-05T22:53:11.865723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./failure-prediction-binary-classification-xgboost.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUDI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./predictive_maintenance.csv',index_col='UDI')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0b009",
   "metadata": {
    "papermill": {
     "duration": 0.004004,
     "end_time": "2023-06-05T22:53:11.962090",
     "exception": false,
     "start_time": "2023-06-05T22:53:11.958086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Product ID is unique for every member of the dataframe, so they contain no usefull data and will be deleted\n",
    "* The next column (Type) shows the quality of the tool used, which is usefull in predicting the life of the tool\n",
    "\n",
    "Remaining columns until Target are all usefull data about the working conditions of the tool\n",
    "\n",
    "* Target column indicates wether the tool has failed (Target==1) or not (Target==0)\n",
    "* Failure Type column shows the same data as the target column, but in the cases where there was a failure it also mentiones the type of the failure the tool has experienced\n",
    "\n",
    "So based on the prediction we are going to make (wether we only want to predict the failure or we want to predict the type sa well), we have to use only one of the last two columns in order to stop any data leakage from happening.\n",
    "The intention of this nptebook is predicting failure, not failure type. Because of this, the failure type column will be deleted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f866508",
   "metadata": {
    "papermill": {
     "duration": 0.01536,
     "end_time": "2023-06-05T22:53:11.981682",
     "exception": false,
     "start_time": "2023-06-05T22:53:11.966322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns = ['Product ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffa79e5",
   "metadata": {
    "papermill": {
     "duration": 1.361208,
     "end_time": "2023-06-05T22:53:13.347458",
     "exception": false,
     "start_time": "2023-06-05T22:53:11.986250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      2\u001b[0m type_enc \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m type_enc\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#encoding 'Type' column to int values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "type_enc = LabelEncoder()\n",
    "df['Type'] = type_enc.fit_transform(df['Type'])\n",
    "#encoding 'Type' column to int values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c630c5",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2023-06-05T22:53:13.358097",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.353126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have to make sure there are no NA values inside the dataframe as well, since if there are any we have to resolve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180044e",
   "metadata": {
    "papermill": {
     "duration": 0.027935,
     "end_time": "2023-06-05T22:53:13.391781",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.363846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df['Target']==1)&(df['Failure Type']=='No Failure')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f46734",
   "metadata": {
    "papermill": {
     "duration": 0.004768,
     "end_time": "2023-06-05T22:53:13.401632",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.396864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In some cases, the data available in the Target column indicates that the tool has failed, but the Failure Type column indicated that the tool has not had any failure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e36539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:13.418006Z",
     "iopub.status.busy": "2023-06-05T22:53:13.417417Z",
     "iopub.status.idle": "2023-06-05T22:53:13.427489Z",
     "shell.execute_reply": "2023-06-05T22:53:13.426486Z"
    },
    "papermill": {
     "duration": 0.02315,
     "end_time": "2023-06-05T22:53:13.429645",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.406495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(df[(df['Target']==1)&(df['Failure Type']=='No Failure')].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287a122a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:13.443877Z",
     "iopub.status.busy": "2023-06-05T22:53:13.443259Z",
     "iopub.status.idle": "2023-06-05T22:53:13.457040Z",
     "shell.execute_reply": "2023-06-05T22:53:13.455679Z"
    },
    "papermill": {
     "duration": 0.02318,
     "end_time": "2023-06-05T22:53:13.459069",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.435889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    9661\n",
       "1     330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first part of the project is to predict whether the tool fails or not, so we drop the failure type\n",
    "#we will address it later\n",
    "df.drop(columns = ['Failure Type'],inplace=True)\n",
    "df.groupby('Target').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860b86b",
   "metadata": {
    "papermill": {
     "duration": 0.004287,
     "end_time": "2023-06-05T22:53:13.468335",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.464048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It can be seen that the dataset is severly imbalanced. So first we divide the dataframe into training and testing sections and then apply oversampling to the training section of the dataset in order to balance the information used for training the model. This is done after dividing the datasets in order to stop any data leakage from happening and also for the testing dataset of the model to be representative of the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d7fbc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:13.479077Z",
     "iopub.status.busy": "2023-06-05T22:53:13.478443Z",
     "iopub.status.idle": "2023-06-05T22:53:13.617138Z",
     "shell.execute_reply": "2023-06-05T22:53:13.615745Z"
    },
    "papermill": {
     "duration": 0.146673,
     "end_time": "2023-06-05T22:53:13.619420",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.472747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#making test and train datasets from the base dataset\n",
    "train_data,test_data = train_test_split(df,stratify=df['Target'],test_size=0.2)\n",
    "#stratifying based on the target column so that the data imbalance of the original dataset is also present in the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389e4006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:13.631831Z",
     "iopub.status.busy": "2023-06-05T22:53:13.631511Z",
     "iopub.status.idle": "2023-06-05T22:53:14.227555Z",
     "shell.execute_reply": "2023-06-05T22:53:14.226043Z"
    },
    "papermill": {
     "duration": 0.604824,
     "end_time": "2023-06-05T22:53:14.229902",
     "exception": false,
     "start_time": "2023-06-05T22:53:13.625078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Oversampling function written with SMOTE to improve group balance in the data\n",
    "def sm_oversamp(inp_x,inp_y):\n",
    "    ov_samp = SMOTE(k_neighbors=4,sampling_strategy='minority')\n",
    "    return ov_samp.fit_resample(inp_x,inp_y)\n",
    "\n",
    "x_train = train_data.drop(columns=['Target'])\n",
    "y_train = train_data['Target']\n",
    "\n",
    "#variables with _os are oversampled and will be used for training the model\n",
    "x_train_os,y_train_os = sm_oversamp(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec52e625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:14.241178Z",
     "iopub.status.busy": "2023-06-05T22:53:14.240818Z",
     "iopub.status.idle": "2023-06-05T22:53:14.255862Z",
     "shell.execute_reply": "2023-06-05T22:53:14.255048Z"
    },
    "papermill": {
     "duration": 0.022908,
     "end_time": "2023-06-05T22:53:14.257784",
     "exception": false,
     "start_time": "2023-06-05T22:53:14.234876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the feature columns to imptove model efficiency\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feature_scaler = MinMaxScaler()\n",
    "#feature scaler is first fit on the features of the training dataset\n",
    "feature_scaler.fit(x_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0abdd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:14.270749Z",
     "iopub.status.busy": "2023-06-05T22:53:14.269691Z",
     "iopub.status.idle": "2023-06-05T22:53:14.288331Z",
     "shell.execute_reply": "2023-06-05T22:53:14.287391Z"
    },
    "papermill": {
     "duration": 0.026595,
     "end_time": "2023-06-05T22:53:14.290063",
     "exception": false,
     "start_time": "2023-06-05T22:53:14.263468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.307918</td>\n",
       "      <td>0.348901</td>\n",
       "      <td>0.584980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.229912</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.383399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.194135</td>\n",
       "      <td>0.541209</td>\n",
       "      <td>0.185771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.227566</td>\n",
       "      <td>0.510989</td>\n",
       "      <td>0.604743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.678461</td>\n",
       "      <td>0.656043</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.623084</td>\n",
       "      <td>0.885375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15452</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310104</td>\n",
       "      <td>0.384539</td>\n",
       "      <td>0.044575</td>\n",
       "      <td>0.902891</td>\n",
       "      <td>0.426877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15453</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.358255</td>\n",
       "      <td>0.480481</td>\n",
       "      <td>0.101466</td>\n",
       "      <td>0.681374</td>\n",
       "      <td>0.833992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778438</td>\n",
       "      <td>0.596420</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.666523</td>\n",
       "      <td>0.569170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778272</td>\n",
       "      <td>0.567216</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>0.576153</td>\n",
       "      <td>0.664032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15456 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5\n",
       "0      1.0  0.913043  0.888889  0.193548  0.510989  0.130435\n",
       "1      1.0  0.489130  0.679012  0.307918  0.348901  0.584980\n",
       "2      0.0  0.347826  0.456790  0.229912  0.442308  0.383399\n",
       "3      1.0  0.445652  0.530864  0.194135  0.541209  0.185771\n",
       "4      0.5  0.347826  0.469136  0.227566  0.510989  0.604743\n",
       "...    ...       ...       ...       ...       ...       ...\n",
       "15451  0.5  0.678461  0.656043  0.073900  0.623084  0.885375\n",
       "15452  1.0  0.310104  0.384539  0.044575  0.902891  0.426877\n",
       "15453  0.5  0.358255  0.480481  0.101466  0.681374  0.833992\n",
       "15454  0.5  0.778438  0.596420  0.085044  0.666523  0.569170\n",
       "15455  0.5  0.778272  0.567216  0.098534  0.576153  0.664032\n",
       "\n",
       "[15456 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature scaler is then applied to the features of both the training and testing datasets\n",
    "train_features_scaled = pd.DataFrame(feature_scaler.transform(x_train_os))\n",
    "test_features_scaled = pd.DataFrame(feature_scaler.transform(test_data.drop(columns=['Target'])))\n",
    "train_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f02de11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:53:14.302391Z",
     "iopub.status.busy": "2023-06-05T22:53:14.302040Z",
     "iopub.status.idle": "2023-06-05T22:54:07.008697Z",
     "shell.execute_reply": "2023-06-05T22:54:07.007866Z"
    },
    "papermill": {
     "duration": 52.720465,
     "end_time": "2023-06-05T22:54:07.015856",
     "exception": false,
     "start_time": "2023-06-05T22:53:14.295391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.001],\n",
       "                                        &#x27;max_depth&#x27;: [2, 5, 8, 10, 12],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 75, 100, 150, 200],\n",
       "                                        &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "                   scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.001],\n",
       "                                        &#x27;max_depth&#x27;: [2, 5, 8, 10, 12],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 75, 100, 150, 200],\n",
       "                                        &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "                   scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   param_distributions={'colsample_bytree': [0.8, 0.9, 1.0],\n",
       "                                        'learning_rate': [0.1, 0.01, 0.001],\n",
       "                                        'max_depth': [2, 5, 8, 10, 12],\n",
       "                                        'n_estimators': [50, 75, 100, 150, 200],\n",
       "                                        'subsample': [0.8, 0.9, 1.0]},\n",
       "                   scoring='recall')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "#XGBClassifier which is based on ensemble learning is chosen for this application\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 75, 100, 150, 200],\n",
    "    'max_depth': [2, 5, 8, 10, 12],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "#for hyperparameter tuning, RandomizedSearchCV is chosen. For filure prediction, recal is the most important scoring method\n",
    "#Because of this it is chosen as the value to be optimized\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=params,\n",
    "    n_iter=10,\n",
    "    scoring='recall',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "random_search.fit(train_features_scaled,y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a20c1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:54:07.028556Z",
     "iopub.status.busy": "2023-06-05T22:54:07.027713Z",
     "iopub.status.idle": "2023-06-05T22:54:07.034153Z",
     "shell.execute_reply": "2023-06-05T22:54:07.033450Z"
    },
    "papermill": {
     "duration": 0.01469,
     "end_time": "2023-06-05T22:54:07.035877",
     "exception": false,
     "start_time": "2023-06-05T22:54:07.021187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0,\n",
       " 'n_estimators': 75,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24a1440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:54:07.048723Z",
     "iopub.status.busy": "2023-06-05T22:54:07.048127Z",
     "iopub.status.idle": "2023-06-05T22:54:07.067503Z",
     "shell.execute_reply": "2023-06-05T22:54:07.066473Z"
    },
    "papermill": {
     "duration": 0.028472,
     "end_time": "2023-06-05T22:54:07.070061",
     "exception": false,
     "start_time": "2023-06-05T22:54:07.041589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1933\n",
      "           1       0.58      0.85      0.69        66\n",
      "\n",
      "    accuracy                           0.97      1999\n",
      "   macro avg       0.79      0.91      0.84      1999\n",
      "weighted avg       0.98      0.97      0.98      1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(test_features_scaled)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_data['Target'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a22ba",
   "metadata": {
    "papermill": {
     "duration": 0.005232,
     "end_time": "2023-06-05T22:54:07.081255",
     "exception": false,
     "start_time": "2023-06-05T22:54:07.076023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.550722,
   "end_time": "2023-06-05T22:54:08.010351",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-05T22:53:02.459629",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
